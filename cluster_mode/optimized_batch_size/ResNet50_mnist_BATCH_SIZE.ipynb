{"cells":[{"cell_type":"code","source":["!pip install tensorflow==1.15.0 tensorflow-datasets==2.1.0\n!pip install tabulate"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42e9d008-f10a-4a34-8f06-d4882e53103d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip uninstall -y h5py"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b048691-2c29-41e1-b862-3a23b6febcf5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nFound existing installation: h5py 3.7.0\nNot uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7c55902d-a051-4ef1-a974-af08851ab1f3\nCan&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nFound existing installation: h5py 3.7.0\nNot uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7c55902d-a051-4ef1-a974-af08851ab1f3\nCan&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip install 'h5py==2.10.0'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4258b71c-5dc8-4e3c-92bd-6bac6568a31a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting h5py==2.10.0\n  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: numpy&gt;=1.7 in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.18.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.14.0)\nInstalling collected packages: h5py\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Not uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7c55902d-a051-4ef1-a974-af08851ab1f3\n    Can&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nSuccessfully installed h5py-2.10.0\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7c55902d-a051-4ef1-a974-af08851ab1f3/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting h5py==2.10.0\n  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: numpy&gt;=1.7 in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.18.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.14.0)\nInstalling collected packages: h5py\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Not uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-7c55902d-a051-4ef1-a974-af08851ab1f3\n    Can&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nSuccessfully installed h5py-2.10.0\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7c55902d-a051-4ef1-a974-af08851ab1f3/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip install keras-nightly"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe0e0c9e-0f1e-4d7c-b10d-42e33a57e600"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting keras-nightly\n  Using cached keras_nightly-2.11.0.dev2022091807-py2.py3-none-any.whl (1.7 MB)\nInstalling collected packages: keras-nightly\nSuccessfully installed keras-nightly-2.11.0.dev2022091807\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7c55902d-a051-4ef1-a974-af08851ab1f3/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting keras-nightly\n  Using cached keras_nightly-2.11.0.dev2022091807-py2.py3-none-any.whl (1.7 MB)\nInstalling collected packages: keras-nightly\nSuccessfully installed keras-nightly-2.11.0.dev2022091807\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7c55902d-a051-4ef1-a974-af08851ab1f3/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["!pip uninstall keras-nightly\n!pip uninstall -y tensorflow\n!pip install keras==2.1.6\n!pip install tensorflow==1.15.0\n!pip install tensorflow-datasets==3.2.1\n!pip install h5py==2.10.0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec4e0f05-cba4-4fb6-8be5-0fb7db9ce664"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Imports"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5928bed6-7197-4162-ab1b-8fa883dd148a"}}},{"cell_type":"code","source":["import argparse\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom bigdl.orca import init_orca_context, stop_orca_context\nfrom bigdl.orca.learn.tf.estimator import Estimator\nfrom bigdl.orca import OrcaContext\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport datetime\nimport time\nfrom bigdl.orca.learn.tf.estimator import Estimator\nfrom tabulate import tabulate\nOrcaContext.log_output = False\n# OrcaContext.log_output = True # recommended to set it to True when running BigDL in Jupyter notebook (this will display terminal's  stdout and stderr in the Jupyter notebook)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21001d77-d68f-4110-ae2c-8ae73a14753e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Prepending /databricks/python/lib/python3.7/site-packages/bigdl/share/dllib/conf/spark-bigdl.conf to sys.path\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/zoo_optimizer.py:73: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n/databricks/python/lib/python3.7/site-packages/bigdl/dllib/utils/nncontext.py:289: UserWarning: Setting log_output takes no effect after the context has been initialized. You need to set log_output before initializing the context (e.g., before calling init_orca_context, init_nncontext, etc.)\n  warnings.warn(msg)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Prepending /databricks/python/lib/python3.7/site-packages/bigdl/share/dllib/conf/spark-bigdl.conf to sys.path\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/zoo_optimizer.py:73: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n/databricks/python/lib/python3.7/site-packages/bigdl/dllib/utils/nncontext.py:289: UserWarning: Setting log_output takes no effect after the context has been initialized. You need to set log_output before initializing the context (e.g., before calling init_orca_context, init_nncontext, etc.)\n  warnings.warn(msg)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Utils"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e391040-d5ae-4349-b86f-be91a6381cb0"}}},{"cell_type":"code","source":["def train_test(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=1, cluster_mode=\"spark-submit\", num_nodes=2, cores=2):\n    init_orca_context(cluster_mode=cluster_mode, num_modes=min(3, num_nodes), cores=min(4, cores))\n    if not model:\n        model = keras.Sequential(\n        [keras.layers.Conv2D(20, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                             input_shape=(28, 28, 1), padding='valid'),\n         keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n         keras.layers.Conv2D(50, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                             padding='valid'),\n         keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n         keras.layers.Flatten(),\n         keras.layers.Dense(500, activation='tanh'),\n         keras.layers.Dense(10, activation='softmax'),\n         ]\n        )\n\n        model.compile(optimizer=keras.optimizers.RMSprop(),\n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])\n    if not (train_data or test_data):\n        if not preprocess:\n            def preprocess(data):\n              data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n              return data['image'], data['label']\n\n        # get DataSet\n        train_data = tfds.load(name=\"mnist\", split=\"train\", data_dir=\"gs://tfds-data/datasets\")\n        test_data = tfds.load(name=\"mnist\", split=\"test\", data_dir=\"gs://tfds-data/datasets\")\n\n        train_data = train_data.map(preprocess)\n        test_data = test_data.map(preprocess)\n    \n    # Disable AutoShard.\n    options = tf.data.Options()\n    options.experimental_distribute.auto_shard = False\n    train_data = train_data.with_options(options)\n    test_data = test_data.with_options(options)\n    \n    est = Estimator.from_keras(keras_model=model)\n    #This will come as an argument for the Function\n    #validation_data will be given as an argument in the Function\n    tic = time.time()\n    est.fit(\n        data=train_data,\n        batch_size=320*num_nodes,\n        epochs=epochs,\n        validation_data=test_data\n    )\n    tac = time.time()\n    fit_time = tac-tic\n    # evaluate and print result\n    # result = est.evaluate(test_data)\n    # print(result)\n    output_name = \"/tmp/\" + (f\"{output_model_name+str(datetime.datetime.now()) if output_model_name else str(datetime.datetime.now())}.h5\")\n    output_name = output_name.replace(\" \", \"_\")\n    if save_model:\n        est.save_keras_model(output_name)\n    # return output_name, fit_time, est\n    return output_name, fit_time\n\ndef save_output(output_model_name, time, result_estimator):\n    print(f\"Saving output to: {output_model_name}\")\n    \ndef visualize_output(output_model_name):\n    print(f\"Visualizing from: {output_model_name}\")\n\ndef train_test_save(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=10, cluster_mode=\"spark-submit\", num_nodes=2, cores=2):\n    output_model_name, fit_time = train_test(\n        model=model,\n        train_data=train_data,\n        test_data=test_data,\n        preprocess=preprocess,\n        output_model_name=output_model_name,\n        epochs=epochs,\n        cluster_mode=cluster_mode,\n        num_nodes=num_nodes,\n        cores=cores,\n        save_model=save_model\n    )\n    print(f\"---->>> {output_model_name}, {num_nodes} nodes, {cores} cores, fitted after {fit_time}sec\")\n    save_output(output_model_name, time, None)\n    visualize_output(output_model_name)\n    return output_model_name, fit_time\n\ndef grid_search(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=10, cluster_mode=\"spark-submit\", min_num_nodes=2, max_num_nodes=3, min_cores=1, max_cores=4):\n    results = []\n    assert min_num_nodes<=max_num_nodes\n    assert min_cores<=max_cores\n    for num_nodes in range(min_num_nodes, max_num_nodes):\n        for cores in range(min_cores, max_cores):\n            model_name, fit_time = train_test_save(\n                model=model,\n                train_data=train_data,\n                test_data=test_data,\n                preprocess=preprocess,\n                output_model_name=output_model_name,\n                epochs=epochs,\n                cluster_mode=cluster_mode,\n                num_nodes=num_nodes,\n                cores=cores,\n                save_model=save_model\n            )\n            results.append((model_name, num_nodes, cores, fit_time))\n    return results\n\ndef visualize_grid_search(model_name, epochs, results):\n    xs, ys = [], []\n    for datum in results:\n        name, nodes, cores, fit_time = datum\n        xs.append(f\"{nodes}, {cores}\")\n        ys.append(fit_time/1000)\n        plt.bar(xs, ys)\n    items = zip(xs, ys)\n    print(items)\n    print(xs, ys)\n    print(tabulate(items, tablefmt=\"github\"))\n    plt.title(f\"{model_name}: {epochs} epochs\")\n    plt.xlabel(\"Nodes, Cores\")\n    plt.ylabel(\"Train time (*10^3 sec)\")\n    plt.plot()\n\ndef tabulate_grid_search(model_name, epochs, results):\n    xs, ys = [], []\n    for datum in results:\n        name, nodes, cores, fit_time = datum\n        xs.append(f\"{nodes}, {cores}\")\n        ys.append(fit_time)\n    items = zip(xs, ys)\n    print(model_name)\n    print(tabulate(items, tablefmt=\"github\", headers=[\"Nodes, Cores\", \"fit_time (sec)\"]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fb2b059-9a51-496d-b861-f202274b1537"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Datasets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2aad5f54-0b5d-4e12-a9a3-a25fe2fc780c"}}},{"cell_type":"code","source":["## MNIST\ndef preprocess(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n    data['image'] = tf.image.resize(data[\"image\"], (72, 72))\n    data['image'] = tf.image.grayscale_to_rgb(data[\"image\"])\n    return data['image'], data['label']\n\n# get DataSet\ntrain_data_mnist = tfds.load(name=\"mnist\", split=\"train\", data_dir=\"gs://tfds-data/datasets\")\ntest_data_mnist = tfds.load(name=\"mnist\", split=\"test\",  data_dir=\"gs://tfds-data/datasets\")\n\ntrain_data_mnist = train_data_mnist.map(preprocess)\ntest_data_mnist = test_data_mnist.map(preprocess)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"273b6232-d2b6-4b9e-ae31-ed1cc817cf96"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_data_mnist"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4ec215cd-2ab4-458f-b958-2ecbca134d06"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[5]: &lt;MapDataset shapes: ((72, 72, 3), ()), types: (tf.float32, tf.int64)&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: &lt;MapDataset shapes: ((72, 72, 3), ()), types: (tf.float32, tf.int64)&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["## Camelyon\ndef preprocess_camelyon(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n    \"\"\"data['image'] = tf.image.resize(data[\"image\"], (72, 72))\n    data['image'] = tf.image.grayscale_to_rgb(data[\"image\"])\"\"\"\n    return data['image'], data['label']\n\ntrain_data = tfds.load(name=\"patch_camelyon\", split=\"train\",  data_dir=\"gs://mybucket-bigdl-ece-ntua\")\ntest_data = tfds.load(name=\"patch_camelyon\", split=\"test\",  data_dir=\"gs://mybucket-bigdl-ece-ntua\")\n\ntrain_data = train_data.map(preprocess_camelyon)\ntest_data = test_data.map(preprocess_camelyon)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb0ad9ad-97ae-416c-94ad-6efa93f65e53"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c54d075-cf79-4e31-a984-b33c7100aefb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[7]: &lt;MapDataset shapes: ((96, 96, 3), ()), types: (tf.float32, tf.int64)&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: &lt;MapDataset shapes: ((96, 96, 3), ()), types: (tf.float32, tf.int64)&gt;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Training for 1 epoch"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10f33f04-4a5d-461c-ab2e-d81fc00f199c"}}},{"cell_type":"code","source":["from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel = ResNet50(weights=None)\nmodel.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n\nname=\"ResNet50\"\ncurrent_train_data = train_data_mnist\ncurrent_test_data = test_data_mnist\nepochs = 1\nmin_num_nodes=1\nmax_num_nodes=4\nmin_cores=4\nmax_cores=5\n\nresults = grid_search(\n    model=model,\n    train_data=current_train_data,\n    test_data=current_test_data,\n    min_num_nodes=min_num_nodes,\n    max_num_nodes=max_num_nodes,\n    min_cores=min_cores,\n    max_cores=max_cores,\n    epochs=epochs,\n    output_model_name=name\n) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d54aec06-73a6-4c2f-8c71-18af77085604"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nInitializing orca context\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\ncreating: createFakeOptimMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpfbi24cav/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpfbi24cav/model\n----&gt;&gt;&gt; /tmp/ResNet502022-09-18_20:52:43.914357.h5, 1 nodes, 4 cores, fitted after 3142.002358675003sec\nSaving output to: /tmp/ResNet502022-09-18_20:52:43.914357.h5\nVisualizing from: /tmp/ResNet502022-09-18_20:52:43.914357.h5\nInitializing orca context\ncreating: createFakeOptimMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpipylyu_q/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpipylyu_q/model\n----&gt;&gt;&gt; /tmp/ResNet502022-09-18_21:42:17.826774.h5, 2 nodes, 4 cores, fitted after 2972.2160835266113sec\nSaving output to: /tmp/ResNet502022-09-18_21:42:17.826774.h5\nVisualizing from: /tmp/ResNet502022-09-18_21:42:17.826774.h5\nInitializing orca context\ncreating: createFakeOptimMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmp5x0n6zo0/model\nINFO:tensorflow:Restoring parameters from /tmp/tmp5x0n6zo0/model\n----&gt;&gt;&gt; /tmp/ResNet502022-09-18_22:36:53.479526.h5, 3 nodes, 4 cores, fitted after 3273.955997467041sec\nSaving output to: /tmp/ResNet502022-09-18_22:36:53.479526.h5\nVisualizing from: /tmp/ResNet502022-09-18_22:36:53.479526.h5\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nInitializing orca context\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\ncreating: createFakeOptimMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpfbi24cav/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpfbi24cav/model\n----&gt;&gt;&gt; /tmp/ResNet502022-09-18_20:52:43.914357.h5, 1 nodes, 4 cores, fitted after 3142.002358675003sec\nSaving output to: /tmp/ResNet502022-09-18_20:52:43.914357.h5\nVisualizing from: /tmp/ResNet502022-09-18_20:52:43.914357.h5\nInitializing orca context\ncreating: createFakeOptimMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpipylyu_q/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpipylyu_q/model\n----&gt;&gt;&gt; /tmp/ResNet502022-09-18_21:42:17.826774.h5, 2 nodes, 4 cores, fitted after 2972.2160835266113sec\nSaving output to: /tmp/ResNet502022-09-18_21:42:17.826774.h5\nVisualizing from: /tmp/ResNet502022-09-18_21:42:17.826774.h5\nInitializing orca context\ncreating: createFakeOptimMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmp5x0n6zo0/model\nINFO:tensorflow:Restoring parameters from /tmp/tmp5x0n6zo0/model\n----&gt;&gt;&gt; /tmp/ResNet502022-09-18_22:36:53.479526.h5, 3 nodes, 4 cores, fitted after 3273.955997467041sec\nSaving output to: /tmp/ResNet502022-09-18_22:36:53.479526.h5\nVisualizing from: /tmp/ResNet502022-09-18_22:36:53.479526.h5\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["visualize_grid_search(\"ResNet50\", epochs, results)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e257f66c-8662-49f8-8aef-fba6e8807ea2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/f1b77a3e-59a0-40c6-952c-cb9dc0d8e793.png","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"code","source":["tabulate_grid_search(\"ResNet50\", epochs, results)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6bae4a9-4ca7-4be2-8347-5995a05e55dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">ResNet50\n| Nodes, Cores   |   fit_time (sec) |\n|----------------|------------------|\n| 1, 4           |          3142    |\n| 2, 4           |          2972.22 |\n| 3, 4           |          3273.96 |\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ResNet50\n Nodes, Cores   |   fit_time (sec) |\n----------------|------------------|\n 1, 4           |          3142    |\n 2, 4           |          2972.22 |\n 3, 4           |          3273.96 |\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ResNet50_mnist_BATCH_SIZE","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3247438261513165}},"nbformat":4,"nbformat_minor":0}
