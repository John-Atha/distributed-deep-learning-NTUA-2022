{"cells":[{"cell_type":"code","source":["!pip install tensorflow==1.15.0 tensorflow-datasets==2.1.0\n!pip install tabulate"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42e9d008-f10a-4a34-8f06-d4882e53103d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip uninstall -y h5py"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b048691-2c29-41e1-b862-3a23b6febcf5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nFound existing installation: h5py 3.7.0\nNot uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-2ffbeac4-fbff-4376-891a-d11c01762698\nCan&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nFound existing installation: h5py 3.7.0\nNot uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-2ffbeac4-fbff-4376-891a-d11c01762698\nCan&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip install 'h5py==2.10.0'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4258b71c-5dc8-4e3c-92bd-6bac6568a31a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting h5py==2.10.0\n  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: numpy&gt;=1.7 in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.18.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.14.0)\nInstalling collected packages: h5py\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Not uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-2ffbeac4-fbff-4376-891a-d11c01762698\n    Can&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nSuccessfully installed h5py-2.10.0\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-2ffbeac4-fbff-4376-891a-d11c01762698/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting h5py==2.10.0\n  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: numpy&gt;=1.7 in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.18.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.14.0)\nInstalling collected packages: h5py\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Not uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-2ffbeac4-fbff-4376-891a-d11c01762698\n    Can&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nSuccessfully installed h5py-2.10.0\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-2ffbeac4-fbff-4376-891a-d11c01762698/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip install keras-nightly"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe0e0c9e-0f1e-4d7c-b10d-42e33a57e600"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting keras-nightly\n  Using cached keras_nightly-2.11.0.dev2022091807-py2.py3-none-any.whl (1.7 MB)\nInstalling collected packages: keras-nightly\nSuccessfully installed keras-nightly-2.11.0.dev2022091807\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-2ffbeac4-fbff-4376-891a-d11c01762698/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting keras-nightly\n  Using cached keras_nightly-2.11.0.dev2022091807-py2.py3-none-any.whl (1.7 MB)\nInstalling collected packages: keras-nightly\nSuccessfully installed keras-nightly-2.11.0.dev2022091807\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-2ffbeac4-fbff-4376-891a-d11c01762698/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["!pip uninstall keras-nightly\n!pip uninstall -y tensorflow\n!pip install keras==2.1.6\n!pip install tensorflow==1.15.0\n!pip install tensorflow-datasets==3.2.1\n!pip install h5py==2.10.0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec4e0f05-cba4-4fb6-8be5-0fb7db9ce664"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Imports"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5928bed6-7197-4162-ab1b-8fa883dd148a"}}},{"cell_type":"code","source":["import argparse\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom bigdl.orca import init_orca_context, stop_orca_context\nfrom bigdl.orca.learn.tf.estimator import Estimator\nfrom bigdl.orca import OrcaContext\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport datetime\nimport time\nfrom bigdl.orca.learn.tf.estimator import Estimator\nfrom tabulate import tabulate\nOrcaContext.log_output = False\n# OrcaContext.log_output = True # recommended to set it to True when running BigDL in Jupyter notebook (this will display terminal's  stdout and stderr in the Jupyter notebook)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21001d77-d68f-4110-ae2c-8ae73a14753e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Prepending /databricks/python/lib/python3.7/site-packages/bigdl/share/dllib/conf/spark-bigdl.conf to sys.path\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/zoo_optimizer.py:73: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n/databricks/python/lib/python3.7/site-packages/bigdl/dllib/utils/nncontext.py:289: UserWarning: Setting log_output takes no effect after the context has been initialized. You need to set log_output before initializing the context (e.g., before calling init_orca_context, init_nncontext, etc.)\n  warnings.warn(msg)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Prepending /databricks/python/lib/python3.7/site-packages/bigdl/share/dllib/conf/spark-bigdl.conf to sys.path\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/zoo_optimizer.py:73: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n/databricks/python/lib/python3.7/site-packages/bigdl/dllib/utils/nncontext.py:289: UserWarning: Setting log_output takes no effect after the context has been initialized. You need to set log_output before initializing the context (e.g., before calling init_orca_context, init_nncontext, etc.)\n  warnings.warn(msg)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Utils"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e391040-d5ae-4349-b86f-be91a6381cb0"}}},{"cell_type":"code","source":["def train_test(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=1, cluster_mode=\"spark-submit\", num_nodes=2, cores=2):\n    init_orca_context(cluster_mode=cluster_mode, num_modes=min(3, num_nodes), cores=min(4, cores))\n    if not model:\n        model = keras.Sequential(\n        [keras.layers.Conv2D(20, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                             input_shape=(28, 28, 1), padding='valid'),\n         keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n         keras.layers.Conv2D(50, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                             padding='valid'),\n         keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n         keras.layers.Flatten(),\n         keras.layers.Dense(500, activation='tanh'),\n         keras.layers.Dense(10, activation='softmax'),\n         ]\n        )\n\n        model.compile(optimizer=keras.optimizers.RMSprop(),\n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])\n    if not (train_data or test_data):\n        if not preprocess:\n            def preprocess(data):\n              data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n              return data['image'], data['label']\n\n        # get DataSet\n        train_data = tfds.load(name=\"mnist\", split=\"train\", data_dir=\"gs://tfds-data/datasets\")\n        test_data = tfds.load(name=\"mnist\", split=\"test\", data_dir=\"gs://tfds-data/datasets\")\n\n        train_data = train_data.map(preprocess)\n        test_data = test_data.map(preprocess)\n    \n    # Disable AutoShard.\n    options = tf.data.Options()\n    options.experimental_distribute.auto_shard = False\n    train_data = train_data.with_options(options)\n    test_data = test_data.with_options(options)\n    \n    est = Estimator.from_keras(keras_model=model)\n    #This will come as an argument for the Function\n    #validation_data will be given as an argument in the Function\n    tic = time.time()\n    est.fit(\n        data=train_data,\n        batch_size=320*num_nodes,\n        epochs=epochs,\n        validation_data=test_data\n    )\n    tac = time.time()\n    fit_time = tac-tic\n    # evaluate and print result\n    # result = est.evaluate(test_data)\n    # print(result)\n    output_name = \"/tmp/\" + (f\"{output_model_name+str(datetime.datetime.now()) if output_model_name else str(datetime.datetime.now())}.h5\")\n    output_name = output_name.replace(\" \", \"_\")\n    if save_model:\n        est.save_keras_model(output_name)\n    # return output_name, fit_time, est\n    return output_name, fit_time\n\ndef save_output(output_model_name, time, result_estimator):\n    print(f\"Saving output to: {output_model_name}\")\n    \ndef visualize_output(output_model_name):\n    print(f\"Visualizing from: {output_model_name}\")\n\ndef train_test_save(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=10, cluster_mode=\"spark-submit\", num_nodes=2, cores=2):\n    output_model_name, fit_time = train_test(\n        model=model,\n        train_data=train_data,\n        test_data=test_data,\n        preprocess=preprocess,\n        output_model_name=output_model_name,\n        epochs=epochs,\n        cluster_mode=cluster_mode,\n        num_nodes=num_nodes,\n        cores=cores,\n        save_model=save_model\n    )\n    print(f\"---->>> {output_model_name}, {num_nodes} nodes, {cores} cores, fitted after {fit_time}sec\")\n    save_output(output_model_name, time, None)\n    visualize_output(output_model_name)\n    return output_model_name, fit_time\n\ndef grid_search(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=10, cluster_mode=\"spark-submit\", min_num_nodes=2, max_num_nodes=3, min_cores=1, max_cores=4):\n    results = []\n    assert min_num_nodes<=max_num_nodes\n    assert min_cores<=max_cores\n    for num_nodes in range(min_num_nodes, max_num_nodes):\n        for cores in range(min_cores, max_cores):\n            model_name, fit_time = train_test_save(\n                model=model,\n                train_data=train_data,\n                test_data=test_data,\n                preprocess=preprocess,\n                output_model_name=output_model_name,\n                epochs=epochs,\n                cluster_mode=cluster_mode,\n                num_nodes=num_nodes,\n                cores=cores,\n                save_model=save_model\n            )\n            results.append((model_name, num_nodes, cores, fit_time))\n    return results\n\ndef visualize_grid_search(model_name, epochs, results):\n    xs, ys = [], []\n    for datum in results:\n        name, nodes, cores, fit_time = datum\n        xs.append(f\"{nodes}, {cores}\")\n        ys.append(fit_time/1000)\n        plt.bar(xs, ys)\n    items = zip(xs, ys)\n    print(items)\n    print(xs, ys)\n    print(tabulate(items, tablefmt=\"github\"))\n    plt.title(f\"{model_name}: {epochs} epochs\")\n    plt.xlabel(\"Nodes, Cores\")\n    plt.ylabel(\"Train time (*10^3 sec)\")\n    plt.plot()\n\ndef tabulate_grid_search(model_name, epochs, results):\n    xs, ys = [], []\n    for datum in results:\n        name, nodes, cores, fit_time = datum\n        xs.append(f\"{nodes}, {cores}\")\n        ys.append(fit_time)\n    items = zip(xs, ys)\n    print(model_name)\n    print(tabulate(items, tablefmt=\"github\", headers=[\"Nodes, Cores\", \"fit_time (sec)\"]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fb2b059-9a51-496d-b861-f202274b1537"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Datasets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2aad5f54-0b5d-4e12-a9a3-a25fe2fc780c"}}},{"cell_type":"code","source":["## MNIST\ndef preprocess(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n#     data['image'] = tf.image.resize(data[\"image\"], (72, 72))\n#     data['image'] = tf.image.grayscale_to_rgb(data[\"image\"])\n    return data['image'], data['label']\n\n# get DataSet\ntrain_data_mnist = tfds.load(name=\"mnist\", split=\"train\", data_dir=\"gs://tfds-data/datasets\")\ntest_data_mnist = tfds.load(name=\"mnist\", split=\"test\",  data_dir=\"gs://tfds-data/datasets\")\n\ntrain_data_mnist = train_data_mnist.map(preprocess)\ntest_data_mnist = test_data_mnist.map(preprocess)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"273b6232-d2b6-4b9e-ae31-ed1cc817cf96"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["## Camelyon\ndef preprocess_camelyon(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n    \"\"\"data['image'] = tf.image.resize(data[\"image\"], (72, 72))\n    data['image'] = tf.image.grayscale_to_rgb(data[\"image\"])\"\"\"\n    return data['image'], data['label']\n\ntrain_data_chamelyon = tfds.load(name=\"patch_camelyon\", split=\"train\",  data_dir=\"gs://mybucket-bigdl-ece-ntua\")\ntest_data_chamelyon = tfds.load(name=\"patch_camelyon\", split=\"test\",  data_dir=\"gs://mybucket-bigdl-ece-ntua\")\n\ntrain_data_chamelyon = train_data_chamelyon.map(preprocess_camelyon)\ntest_data_chamelyon = test_data_chamelyon.map(preprocess_camelyon)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb0ad9ad-97ae-416c-94ad-6efa93f65e53"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Training for 1 epoch"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b22f72d9-3d4c-49d4-9d08-e621bd221f58"}}},{"cell_type":"code","source":["name = \"SimpleCNN\"\n\nepochs = 1\nmin_num_nodes = 1\nmax_num_nodes = 4\nmin_cores = 4\nmax_cores = 5\n\ncurrent_training_data = train_data_mnist\ncurrent_test_data = test_data_mnist\n\nresults = grid_search(\n    min_num_nodes=min_num_nodes,\n    max_num_nodes=max_num_nodes,\n    min_cores=min_cores,\n    max_cores=max_cores,\n    epochs=epochs,\n    train_data=current_training_data,\n    test_data=current_test_data,\n    output_model_name=\"simple\"\n)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ee4758c-e84e-464d-a502-90dd64ea6102"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Initializing orca context\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:163: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:163: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpaf41pysf/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpaf41pysf/model\n----&gt;&gt;&gt; /tmp/simple2022-09-18_19:54:47.155265.h5, 1 nodes, 4 cores, fitted after 98.79277729988098sec\nSaving output to: /tmp/simple2022-09-18_19:54:47.155265.h5\nVisualizing from: /tmp/simple2022-09-18_19:54:47.155265.h5\nInitializing orca context\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmp9qmv90f7/model\nINFO:tensorflow:Restoring parameters from /tmp/tmp9qmv90f7/model\n----&gt;&gt;&gt; /tmp/simple2022-09-18_19:56:12.008263.h5, 2 nodes, 4 cores, fitted after 83.03343081474304sec\nSaving output to: /tmp/simple2022-09-18_19:56:12.008263.h5\nVisualizing from: /tmp/simple2022-09-18_19:56:12.008263.h5\nInitializing orca context\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpxcxwae3_/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpxcxwae3_/model\n----&gt;&gt;&gt; /tmp/simple2022-09-18_19:57:32.652065.h5, 3 nodes, 4 cores, fitted after 78.91799879074097sec\nSaving output to: /tmp/simple2022-09-18_19:57:32.652065.h5\nVisualizing from: /tmp/simple2022-09-18_19:57:32.652065.h5\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Initializing orca context\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:163: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:163: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpaf41pysf/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpaf41pysf/model\n----&gt;&gt;&gt; /tmp/simple2022-09-18_19:54:47.155265.h5, 1 nodes, 4 cores, fitted after 98.79277729988098sec\nSaving output to: /tmp/simple2022-09-18_19:54:47.155265.h5\nVisualizing from: /tmp/simple2022-09-18_19:54:47.155265.h5\nInitializing orca context\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmp9qmv90f7/model\nINFO:tensorflow:Restoring parameters from /tmp/tmp9qmv90f7/model\n----&gt;&gt;&gt; /tmp/simple2022-09-18_19:56:12.008263.h5, 2 nodes, 4 cores, fitted after 83.03343081474304sec\nSaving output to: /tmp/simple2022-09-18_19:56:12.008263.h5\nVisualizing from: /tmp/simple2022-09-18_19:56:12.008263.h5\nInitializing orca context\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpxcxwae3_/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpxcxwae3_/model\n----&gt;&gt;&gt; /tmp/simple2022-09-18_19:57:32.652065.h5, 3 nodes, 4 cores, fitted after 78.91799879074097sec\nSaving output to: /tmp/simple2022-09-18_19:57:32.652065.h5\nVisualizing from: /tmp/simple2022-09-18_19:57:32.652065.h5\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["visualize_grid_search(\"Simple CNN\", epochs, results)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e257f66c-8662-49f8-8aef-fba6e8807ea2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/89377762-2234-441b-a72f-48f76be4da9a.png","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"code","source":["tabulate_grid_search(\"Simple CNN\", epochs, results)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6bae4a9-4ca7-4be2-8347-5995a05e55dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Simple CNN\n| Nodes, Cores   |   fit_time (sec) |\n|----------------|------------------|\n| 1, 4           |          98.7928 |\n| 2, 4           |          83.0334 |\n| 3, 4           |          78.918  |\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Simple CNN\n Nodes, Cores   |   fit_time (sec) |\n----------------|------------------|\n 1, 4           |          98.7928 |\n 2, 4           |          83.0334 |\n 3, 4           |          78.918  |\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Simple_CNN_mnist_BATCH_SIZE","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3247438261513140}},"nbformat":4,"nbformat_minor":0}
