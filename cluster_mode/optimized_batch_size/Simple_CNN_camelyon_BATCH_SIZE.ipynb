{"cells":[{"cell_type":"code","source":["!pip install tensorflow==1.15.0 tensorflow-datasets==2.1.0\n!pip install tabulate"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42e9d008-f10a-4a34-8f06-d4882e53103d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip uninstall -y h5py"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b048691-2c29-41e1-b862-3a23b6febcf5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nFound existing installation: h5py 3.7.0\nNot uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3af1d696-1e21-42c5-a52a-6ca3e16e742a\nCan&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nFound existing installation: h5py 3.7.0\nNot uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3af1d696-1e21-42c5-a52a-6ca3e16e742a\nCan&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip install 'h5py==2.10.0'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4258b71c-5dc8-4e3c-92bd-6bac6568a31a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting h5py==2.10.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: numpy&gt;=1.7 in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.18.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.14.0)\nInstalling collected packages: h5py\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Not uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3af1d696-1e21-42c5-a52a-6ca3e16e742a\n    Can&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nSuccessfully installed h5py-2.10.0\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-3af1d696-1e21-42c5-a52a-6ca3e16e742a/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting h5py==2.10.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: numpy&gt;=1.7 in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.18.1)\nRequirement already satisfied: six in /databricks/python3/lib/python3.7/site-packages (from h5py==2.10.0) (1.14.0)\nInstalling collected packages: h5py\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Not uninstalling h5py at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3af1d696-1e21-42c5-a52a-6ca3e16e742a\n    Can&#39;t uninstall &#39;h5py&#39;. No files were found to uninstall.\nSuccessfully installed h5py-2.10.0\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-3af1d696-1e21-42c5-a52a-6ca3e16e742a/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip install keras-nightly"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fe0e0c9e-0f1e-4d7c-b10d-42e33a57e600"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting keras-nightly\n  Downloading keras_nightly-2.11.0.dev2022091907-py2.py3-none-any.whl (1.7 MB)\nInstalling collected packages: keras-nightly\nSuccessfully installed keras-nightly-2.11.0.dev2022091907\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-3af1d696-1e21-42c5-a52a-6ca3e16e742a/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting keras-nightly\n  Downloading keras_nightly-2.11.0.dev2022091907-py2.py3-none-any.whl (1.7 MB)\nInstalling collected packages: keras-nightly\nSuccessfully installed keras-nightly-2.11.0.dev2022091907\nWARNING: You are using pip version 20.0.2; however, version 22.2.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-3af1d696-1e21-42c5-a52a-6ca3e16e742a/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["!pip uninstall keras-nightly\n!pip uninstall -y tensorflow\n!pip install keras==2.1.6\n!pip install tensorflow==1.15.0\n!pip install tensorflow-datasets==3.2.1\n!pip install h5py==2.10.0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec4e0f05-cba4-4fb6-8be5-0fb7db9ce664"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Imports"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5928bed6-7197-4162-ab1b-8fa883dd148a"}}},{"cell_type":"code","source":["import argparse\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom bigdl.orca import init_orca_context, stop_orca_context\nfrom bigdl.orca.learn.tf.estimator import Estimator\nfrom bigdl.orca import OrcaContext\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport datetime\nimport time\nfrom bigdl.orca.learn.tf.estimator import Estimator\nfrom tabulate import tabulate\nOrcaContext.log_output = False\n# OrcaContext.log_output = True # recommended to set it to True when running BigDL in Jupyter notebook (this will display terminal's  stdout and stderr in the Jupyter notebook)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21001d77-d68f-4110-ae2c-8ae73a14753e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Prepending /databricks/python/lib/python3.7/site-packages/bigdl/share/dllib/conf/spark-bigdl.conf to sys.path\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/zoo_optimizer.py:73: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n/databricks/python/lib/python3.7/site-packages/bigdl/dllib/utils/nncontext.py:289: UserWarning: Setting log_output takes no effect after the context has been initialized. You need to set log_output before initializing the context (e.g., before calling init_orca_context, init_nncontext, etc.)\n  warnings.warn(msg)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Prepending /databricks/python/lib/python3.7/site-packages/bigdl/share/dllib/conf/spark-bigdl.conf to sys.path\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/zoo_optimizer.py:73: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n/databricks/python/lib/python3.7/site-packages/bigdl/dllib/utils/nncontext.py:289: UserWarning: Setting log_output takes no effect after the context has been initialized. You need to set log_output before initializing the context (e.g., before calling init_orca_context, init_nncontext, etc.)\n  warnings.warn(msg)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Utils"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e391040-d5ae-4349-b86f-be91a6381cb0"}}},{"cell_type":"code","source":["def train_test(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=1, cluster_mode=\"spark-submit\", num_nodes=2, cores=2):\n    init_orca_context(cluster_mode=cluster_mode, num_modes=min(3, num_nodes), cores=min(4, cores))\n    if not model:\n        model = keras.Sequential(\n        [keras.layers.Conv2D(20, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                             input_shape=(96, 96, 3), padding='valid'),\n         keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n         keras.layers.Conv2D(50, kernel_size=(5, 5), strides=(1, 1), activation='tanh',\n                             padding='valid'),\n         keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n         keras.layers.Flatten(),\n         keras.layers.Dense(500, activation='tanh'),\n         keras.layers.Dense(10, activation='softmax'),\n         ]\n        )\n\n        model.compile(optimizer=keras.optimizers.RMSprop(),\n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])\n    if not (train_data or test_data):\n        if not preprocess:\n            def preprocess(data):\n              data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n              return data['image'], data['label']\n\n        # get DataSet\n        train_data = tfds.load(name=\"mnist\", split=\"train\", data_dir=\"gs://tfds-data/datasets\")\n        test_data = tfds.load(name=\"mnist\", split=\"test\", data_dir=\"gs://tfds-data/datasets\")\n\n        train_data = train_data.map(preprocess)\n        test_data = test_data.map(preprocess)\n    \n    # Disable AutoShard.\n    options = tf.data.Options()\n    options.experimental_distribute.auto_shard = False\n    train_data = train_data.with_options(options)\n    test_data = test_data.with_options(options)\n    \n    est = Estimator.from_keras(keras_model=model)\n    #This will come as an argument for the Function\n    #validation_data will be given as an argument in the Function\n    tic = time.time()\n    est.fit(\n        data=train_data,\n        batch_size=320*num_nodes,\n        epochs=epochs,\n        validation_data=test_data\n    )\n    tac = time.time()\n    fit_time = tac-tic\n    # evaluate and print result\n    # result = est.evaluate(test_data)\n    # print(result)\n    output_name = \"/tmp/\" + (f\"{output_model_name+str(datetime.datetime.now()) if output_model_name else str(datetime.datetime.now())}.h5\")\n    output_name = output_name.replace(\" \", \"_\")\n    if save_model:\n        est.save_keras_model(output_name)\n    # return output_name, fit_time, est\n    return output_name, fit_time\n\ndef save_output(output_model_name, time, result_estimator):\n    print(f\"Saving output to: {output_model_name}\")\n    \ndef visualize_output(output_model_name):\n    print(f\"Visualizing from: {output_model_name}\")\n\ndef train_test_save(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=10, cluster_mode=\"spark-submit\", num_nodes=2, cores=2):\n    output_model_name, fit_time = train_test(\n        model=model,\n        train_data=train_data,\n        test_data=test_data,\n        preprocess=preprocess,\n        output_model_name=output_model_name,\n        epochs=epochs,\n        cluster_mode=cluster_mode,\n        num_nodes=num_nodes,\n        cores=cores,\n        save_model=save_model\n    )\n    print(f\"---->>> {output_model_name}, {num_nodes} nodes, {cores} cores, fitted after {fit_time}sec\")\n    save_output(output_model_name, time, None)\n    visualize_output(output_model_name)\n    return output_model_name, fit_time\n\ndef grid_search(model=None, train_data=None, test_data=None, preprocess=None, output_model_name=None, save_model=False, epochs=10, cluster_mode=\"spark-submit\", min_num_nodes=2, max_num_nodes=3, min_cores=1, max_cores=4):\n    results = []\n    assert min_num_nodes<=max_num_nodes\n    assert min_cores<=max_cores\n    for num_nodes in range(min_num_nodes, max_num_nodes):\n        for cores in range(min_cores, max_cores):\n            model_name, fit_time = train_test_save(\n                model=model,\n                train_data=train_data,\n                test_data=test_data,\n                preprocess=preprocess,\n                output_model_name=output_model_name,\n                epochs=epochs,\n                cluster_mode=cluster_mode,\n                num_nodes=num_nodes,\n                cores=cores,\n                save_model=save_model\n            )\n            results.append((model_name, num_nodes, cores, fit_time))\n    return results\n\ndef visualize_grid_search(model_name, epochs, results):\n    xs, ys = [], []\n    for datum in results:\n        name, nodes, cores, fit_time = datum\n        xs.append(f\"{nodes}, {cores}\")\n        ys.append(fit_time/1000)\n        plt.bar(xs, ys)\n    items = zip(xs, ys)\n    print(items)\n    print(xs, ys)\n    print(tabulate(items, tablefmt=\"github\"))\n    plt.title(f\"{model_name}: {epochs} epochs\")\n    plt.xlabel(\"Nodes, Cores\")\n    plt.ylabel(\"Train time (*10^3 sec)\")\n    plt.plot()\n\ndef tabulate_grid_search(model_name, epochs, results):\n    xs, ys = [], []\n    for datum in results:\n        name, nodes, cores, fit_time = datum\n        xs.append(f\"{nodes}, {cores}\")\n        ys.append(fit_time)\n    items = zip(xs, ys)\n    print(model_name)\n    print(tabulate(items, tablefmt=\"github\", headers=[\"Nodes, Cores\", \"fit_time (sec)\"]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fb2b059-9a51-496d-b861-f202274b1537"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Datasets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2aad5f54-0b5d-4e12-a9a3-a25fe2fc780c"}}},{"cell_type":"code","source":["## MNIST\ndef preprocess(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n#     data['image'] = tf.image.resize(data[\"image\"], (72, 72))\n#     data['image'] = tf.image.grayscale_to_rgb(data[\"image\"])\n    return data['image'], data['label']\n\n# get DataSet\ntrain_data_mnist = tfds.load(name=\"mnist\", split=\"train\", data_dir=\"gs://tfds-data/datasets\")\ntest_data_mnist = tfds.load(name=\"mnist\", split=\"test\",  data_dir=\"gs://tfds-data/datasets\")\n\ntrain_data_mnist = train_data_mnist.map(preprocess)\ntest_data_mnist = test_data_mnist.map(preprocess)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"273b6232-d2b6-4b9e-ae31-ed1cc817cf96"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["## Camelyon\ndef preprocess_camelyon(data):\n    data['image'] = tf.cast(data[\"image\"], tf.float32) / 255.\n    \"\"\"data['image'] = tf.image.resize(data[\"image\"], (72, 72))\n    data['image'] = tf.image.grayscale_to_rgb(data[\"image\"])\"\"\"\n    return data['image'], data['label']\n\ntrain_data_chamelyon = tfds.load(name=\"patch_camelyon\", split=\"train\",  data_dir=\"gs://mybucket-bigdl-ece-ntua\")\ntest_data_chamelyon = tfds.load(name=\"patch_camelyon\", split=\"test\",  data_dir=\"gs://mybucket-bigdl-ece-ntua\")\n\ntrain_data_chamelyon = train_data_chamelyon.map(preprocess_camelyon)\ntest_data_chamelyon = test_data_chamelyon.map(preprocess_camelyon)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eb0ad9ad-97ae-416c-94ad-6efa93f65e53"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_data_chamelyon"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"00cbc578-8096-4513-b34d-0d0bc48d679e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: &lt;MapDataset shapes: ((96, 96, 3), ()), types: (tf.float32, tf.int64)&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: &lt;MapDataset shapes: ((96, 96, 3), ()), types: (tf.float32, tf.int64)&gt;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Training for 1 epoch"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b22f72d9-3d4c-49d4-9d08-e621bd221f58"}}},{"cell_type":"code","source":["name = \"SimpleCNN\"\n\nepochs = 1\nmin_num_nodes = 1\nmax_num_nodes = 4\nmin_cores = 4\nmax_cores = 5\n\ncurrent_training_data = train_data_chamelyon\ncurrent_test_data = test_data_chamelyon\n\nresults = grid_search(\n    min_num_nodes=min_num_nodes,\n    max_num_nodes=max_num_nodes,\n    min_cores=min_cores,\n    max_cores=max_cores,\n    epochs=epochs,\n    train_data=current_training_data,\n    test_data=current_test_data,\n    output_model_name=\"simple\"\n)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ee4758c-e84e-464d-a502-90dd64ea6102"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Initializing orca context\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:163: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:163: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpgu5449_u/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpgu5449_u/model\n----&gt;&gt;&gt; /tmp/simple2022-09-19_19:29:39.496188.h5, 1 nodes, 4 cores, fitted after 2398.0458364486694sec\nSaving output to: /tmp/simple2022-09-19_19:29:39.496188.h5\nVisualizing from: /tmp/simple2022-09-19_19:29:39.496188.h5\nInitializing orca context\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpagatcku9/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpagatcku9/model\n----&gt;&gt;&gt; /tmp/simple2022-09-19_20:04:01.838112.h5, 2 nodes, 4 cores, fitted after 2060.233711242676sec\nSaving output to: /tmp/simple2022-09-19_20:04:01.838112.h5\nVisualizing from: /tmp/simple2022-09-19_20:04:01.838112.h5\nInitializing orca context\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmponpl1o6i/model\nINFO:tensorflow:Restoring parameters from /tmp/tmponpl1o6i/model\n----&gt;&gt;&gt; /tmp/simple2022-09-19_20:37:05.907987.h5, 3 nodes, 4 cores, fitted after 1982.123159646988sec\nSaving output to: /tmp/simple2022-09-19_20:37:05.907987.h5\nVisualizing from: /tmp/simple2022-09-19_20:37:05.907987.h5\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Initializing orca context\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:751: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:818: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:851: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_dataset.py:216: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:669: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:299: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.cast` instead.\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:163: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:163: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:191: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:206: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:247: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\nWARNING:tensorflow:From /databricks/python/lib/python3.7/site-packages/bigdl/orca/tfpark/tf_optimizer.py:289: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpgu5449_u/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpgu5449_u/model\n----&gt;&gt;&gt; /tmp/simple2022-09-19_19:29:39.496188.h5, 1 nodes, 4 cores, fitted after 2398.0458364486694sec\nSaving output to: /tmp/simple2022-09-19_19:29:39.496188.h5\nVisualizing from: /tmp/simple2022-09-19_19:29:39.496188.h5\nInitializing orca context\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmpagatcku9/model\nINFO:tensorflow:Restoring parameters from /tmp/tmpagatcku9/model\n----&gt;&gt;&gt; /tmp/simple2022-09-19_20:04:01.838112.h5, 2 nodes, 4 cores, fitted after 2060.233711242676sec\nSaving output to: /tmp/simple2022-09-19_20:04:01.838112.h5\nVisualizing from: /tmp/simple2022-09-19_20:04:01.838112.h5\nInitializing orca context\ncreating: createZooKerasSparseCategoricalCrossEntropy\ncreating: createLoss\ncreating: createZooKerasSparseCategoricalAccuracy\ncreating: createFakeOptimMethod\ncreating: createTFValidationMethod\ncreating: createTFValidationMethod\ncreating: createTFTrainingHelper\ncreating: createIdentityCriterion\ncreating: createEstimator\ncreating: createMaxEpoch\ncreating: createEveryEpoch\nINFO:tensorflow:Restoring parameters from /tmp/tmponpl1o6i/model\nINFO:tensorflow:Restoring parameters from /tmp/tmponpl1o6i/model\n----&gt;&gt;&gt; /tmp/simple2022-09-19_20:37:05.907987.h5, 3 nodes, 4 cores, fitted after 1982.123159646988sec\nSaving output to: /tmp/simple2022-09-19_20:37:05.907987.h5\nVisualizing from: /tmp/simple2022-09-19_20:37:05.907987.h5\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["visualize_grid_search(\"Simple CNN\", epochs, results)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e257f66c-8662-49f8-8aef-fba6e8807ea2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/plots/7465977f-96d2-4863-8d7a-34b508efdbd8.png","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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"}}],"execution_count":0},{"cell_type":"code","source":["tabulate_grid_search(\"Simple CNN\", epochs, results)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6bae4a9-4ca7-4be2-8347-5995a05e55dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Simple CNN\n| Nodes, Cores   |   fit_time (sec) |\n|----------------|------------------|\n| 1, 4           |          2398.05 |\n| 2, 4           |          2060.23 |\n| 3, 4           |          1982.12 |\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Simple CNN\n Nodes, Cores   |   fit_time (sec) |\n----------------|------------------|\n 1, 4           |          2398.05 |\n 2, 4           |          2060.23 |\n 3, 4           |          1982.12 |\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4366c16-a8b9-41c2-8ae9-85a1a899383d"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Simple_CNN_camelyon_BATCH_SIZE","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3778436982945802}},"nbformat":4,"nbformat_minor":0}
